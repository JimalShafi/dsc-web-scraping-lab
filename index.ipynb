{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Now that you've seen a more extensive example of developing a web scraping script, it's time to further practice and formalize that knowledge by writing functions to parse specific pieces of information from the web page and then synthesizing these into a larger loop that will iterate over successive web pages in order to build a complete dataset.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Navigate HTML documents using Beautiful Soup's children and sibling relations\n",
    "* Select specific elements from HTML using Beautiful Soup\n",
    "* Use regular expressions to extract items with a certain pattern within Beautiful Soup\n",
    "* Determine the pagination scheme of a website and scrape multiple pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Overview\n",
    "\n",
    "This lab will build upon the previous lesson. In the end, you'll look to write a script that will iterate over all of the pages for the demo site and extract the title, price, star rating and availability of each book listed. Building up to that, you'll formalize the concepts from the lesson by writing functions that will extract a list of each of these features for each web page. You'll then combine these functions into the full script which will look something like this:  \n",
    "\n",
    "```python\n",
    "df = pd.DataFrame()\n",
    "for i in range(2,51):\n",
    "    url = \"http://books.toscrape.com/catalogue/page-{}.html\".format(i)\n",
    "    soup = BeautifulSoup(html_page.content, 'html.parser')\n",
    "    new_titles = retrieve_titles(soup)\n",
    "    new_star_ratings = retrieve_ratings(soup)\n",
    "    new_prices = retrieve_prices(soup)\n",
    "    new_avails = retrieve_avails(soup)\n",
    "    ...\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Titles\n",
    "\n",
    "To start, write a function that extracts the titles of the books on a given page. The input for the function should be the `soup` for the HTML of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_titles(soup):\n",
    "    #Your code here\n",
    "  import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def retrieve_titles(soup):\n",
    "    titles = []\n",
    "    # Find all the h3 tags with class 'title'\n",
    "    title_tags = soup.find_all('h3', class_='title')\n",
    "    # Extract the text from each title tag and append to the titles list\n",
    "    for title_tag in title_tags:\n",
    "        titles.append(title_tag.text.strip())\n",
    "    return titles\n",
    "\n",
    "def retrieve_ratings(soup):\n",
    "    ratings = []\n",
    "    # Find all the p tags with class 'star-rating'\n",
    "    rating_tags = soup.find_all('p', class_='star-rating')\n",
    "    # Extract the star rating from each tag and append to the ratings list\n",
    "    for rating_tag in rating_tags:\n",
    "        # Extract the class attribute to get the star rating\n",
    "        rating = rating_tag['class'][-1]\n",
    "        ratings.append(rating)\n",
    "    return ratings\n",
    "\n",
    "def retrieve_prices(soup):\n",
    "    prices = []\n",
    "    # Find all the p tags with class 'price_color'\n",
    "    price_tags = soup.find_all('p', class_='price_color')\n",
    "    # Extract the price from each tag and append to the prices list\n",
    "    for price_tag in price_tags:\n",
    "        prices.append(price_tag.text.strip()[1:])  # Remove the currency symbol\n",
    "    return prices\n",
    "\n",
    "def retrieve_avails(soup):\n",
    "    avails = []\n",
    "    # Find all the p tags with c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Ratings\n",
    "\n",
    "Next, write a similar function to retrieve the star ratings on a given page. Again, the function should take in the `soup` from the given HTML page and return a list of the star ratings for the books. These star ratings should be formatted as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_ratings(soup):\n",
    "    #Your code here\n",
    "    ratings = []\n",
    "    # Find all the p tags with class 'star-rating'\n",
    "    rating_tags = soup.find_all('p', class_='star-rating')\n",
    "    # Extract the star rating from each tag and append to the ratings list\n",
    "    for rating_tag in rating_tags:\n",
    "        # Extract the class attribute to get the star rating\n",
    "        rating_classes = rating_tag.get('class')\n",
    "        # The star rating is the last class in the list\n",
    "        rating = rating_classes[-1]\n",
    "        # Map the textual representation to an integer value\n",
    "        rating_map = {'One': 1, 'Two': 2, 'Three': 3, 'Four': 4, 'Five': 5}\n",
    "        ratings.append(rating_map[rating])\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Prices\n",
    "\n",
    "Now write a function to retrieve the prices on a given page. The function should take in the `soup` from the given page and return a list of prices formatted as floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prices: [51.77, 53.74, 50.1, 47.82, 54.23, 22.65, 33.34, 17.93, 22.6, 52.15, 13.99, 20.66, 17.46, 52.29, 35.02, 57.25, 23.88, 37.59, 51.33, 45.17]\n",
      "Titles: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def retrieve_prices(soup):\n",
    "    prices = []\n",
    "    # Find all the p tags with class 'price_color'\n",
    "    price_tags = soup.find_all('p', class_='price_color')\n",
    "    # Extract the price from each tag and append to the prices list\n",
    "    for price_tag in price_tags:\n",
    "        # Remove the currency symbol and convert to float\n",
    "        price = float(price_tag.text.strip()[1:])\n",
    "        prices.append(price)\n",
    "    return prices\n",
    "\n",
    "def retrieve_titles(soup):\n",
    "    titles = []\n",
    "    # Find all the h3 tags with class 'title'\n",
    "    title_tags = soup.find_all('h3', class_='title')\n",
    "    # Extract the text from each title tag and append to the titles list\n",
    "    for title_tag in title_tags:\n",
    "        titles.append(title_tag.text.strip())\n",
    "    return titles\n",
    "\n",
    "# Define the URL of the page to scrape\n",
    "url = \"http://books.toscrape.com/catalogue/page-1.html\"\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "# Create a BeautifulSoup object from the HTML content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Retrieve prices from the page\n",
    "prices = retrieve_prices(soup)\n",
    "print(\"Prices:\", prices)\n",
    "\n",
    "# Retrieve titles from the page\n",
    "titles = retrieve_titles(soup)\n",
    "print(\"Titles:\", titles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Availability\n",
    "\n",
    "Write a function to retrieve whether each book is available or not. The function should take in the `soup` from a given html page and return a list of the availability for each book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Title, Star Rating, Price, Availability]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def retrieve_prices(soup):\n",
    "    prices = []\n",
    "    price_tags = soup.find_all('p', class_='price_color')\n",
    "    for price_tag in price_tags:\n",
    "        price = float(price_tag.text.strip()[1:])\n",
    "        prices.append(price)\n",
    "    return prices\n",
    "\n",
    "def retrieve_titles(soup):\n",
    "    titles = []\n",
    "    title_tags = soup.find_all('h3', class_='title')\n",
    "    for title_tag in title_tags:\n",
    "        titles.append(title_tag.text.strip())\n",
    "    return titles\n",
    "\n",
    "def retrieve_ratings(soup):\n",
    "    ratings = []\n",
    "    rating_tags = soup.find_all('p', class_='star-rating')\n",
    "    rating_map = {'One': 1, 'Two': 2, 'Three': 3, 'Four': 4, 'Five': 5}\n",
    "    for rating_tag in rating_tags:\n",
    "        rating = rating_map[rating_tag.get('class')[-1]]\n",
    "        ratings.append(rating)\n",
    "    return ratings\n",
    "\n",
    "def retrieve_availabilities(soup):\n",
    "    availabilities = []\n",
    "    availability_tags = soup.find_all('p', class_='instock availability')\n",
    "    for availability_tag in availability_tags:\n",
    "        availabilities.append(availability_tag.text.strip())\n",
    "    return availabilities\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i in range(1, 51):\n",
    "    url = \"http://books.toscrape.com/catalogue/page-{}.html\".format(i)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    titles = retrieve_titles(soup)\n",
    "    star_ratings = retrieve_ratings(soup)\n",
    "    prices = retrieve_prices(soup)\n",
    "    availabilities = retrieve_availabilities(soup)\n",
    "    \n",
    "    # Ensure all arrays have the same length\n",
    "    min_length = min(len(titles), len(star_ratings), len(prices), len(availabilities))\n",
    "    titles = titles[:min_length]\n",
    "    star_ratings = star_ratings[:min_length]\n",
    "    prices = prices[:min_length]\n",
    "    availabilities = availabilities[:min_length]\n",
    "    \n",
    "    page_df = pd.DataFrame({\n",
    "        'Title': titles,\n",
    "        'Star Rating': star_ratings,\n",
    "        'Price': prices,\n",
    "        'Availability': availabilities\n",
    "    })\n",
    "    df = pd.concat([df, page_df], ignore_index=True)\n",
    "\n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Script to Retrieve All the Books From All 50 Pages\n",
    "\n",
    "Finally, write a script to retrieve all of the information from all 50 pages of the books.toscrape.com website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping and saving complete.\n"
     ]
    }
   ],
   "source": [
    "#Your code here\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def retrieve_prices(soup):\n",
    "    prices = []\n",
    "    price_tags = soup.find_all('p', class_='price_color')\n",
    "    for price_tag in price_tags:\n",
    "        price = float(price_tag.text.strip()[1:])\n",
    "        prices.append(price)\n",
    "    return prices\n",
    "\n",
    "def retrieve_titles(soup):\n",
    "    titles = []\n",
    "    title_tags = soup.find_all('h3', class_='title')\n",
    "    for title_tag in title_tags:\n",
    "        titles.append(title_tag.text.strip())\n",
    "    return titles\n",
    "\n",
    "def retrieve_ratings(soup):\n",
    "    ratings = []\n",
    "    rating_tags = soup.find_all('p', class_='star-rating')\n",
    "    rating_map = {'One': 1, 'Two': 2, 'Three': 3, 'Four': 4, 'Five': 5}\n",
    "    for rating_tag in rating_tags:\n",
    "        rating = rating_map[rating_tag.get('class')[-1]]\n",
    "        ratings.append(rating)\n",
    "    return ratings\n",
    "\n",
    "def retrieve_availabilities(soup):\n",
    "    availabilities = []\n",
    "    availability_tags = soup.find_all('p', class_='instock availability')\n",
    "    for availability_tag in availability_tags:\n",
    "        availabilities.append(availability_tag.text.strip())\n",
    "    return availabilities\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i in range(1, 51):\n",
    "    url = \"http://books.toscrape.com/catalogue/page-{}.html\".format(i)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    titles = retrieve_titles(soup)\n",
    "    star_ratings = retrieve_ratings(soup)\n",
    "    prices = retrieve_prices(soup)\n",
    "    availabilities = retrieve_availabilities(soup)\n",
    "    \n",
    "    min_length = min(len(titles), len(star_ratings), len(prices), len(availabilities))\n",
    "    titles = titles[:min_length]\n",
    "    star_ratings = star_ratings[:min_length]\n",
    "    prices = prices[:min_length]\n",
    "    availabilities = availabilities[:min_length]\n",
    "    \n",
    "    page_df = pd.DataFrame({\n",
    "        'Title': titles,\n",
    "        'Star Rating': star_ratings,\n",
    "        'Price': prices,\n",
    "        'Availability': availabilities\n",
    "    })\n",
    "    df = pd.concat([df, page_df], ignore_index=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('books_data.csv', index=False)\n",
    "\n",
    "print(\"Scraping and saving complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level-Up: Write a new version of the script you just wrote. \n",
    "\n",
    "If you used URL hacking to generate each successive page URL, instead write a function that retrieves the link from the `\"next\"` button at the bottom of the page. Conversely, if you already used this approach above, use URL-hacking (arguably the easier of the two methods in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping and saving complete.\n"
     ]
    }
   ],
   "source": [
    "#Your code here\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def retrieve_prices(soup):\n",
    "    prices = []\n",
    "    price_tags = soup.find_all('p', class_='price_color')\n",
    "    for price_tag in price_tags:\n",
    "        price = float(price_tag.text.strip()[1:])\n",
    "        prices.append(price)\n",
    "    return prices\n",
    "\n",
    "def retrieve_titles(soup):\n",
    "    titles = []\n",
    "    title_tags = soup.find_all('h3', class_='title')\n",
    "    for title_tag in title_tags:\n",
    "        titles.append(title_tag.text.strip())\n",
    "    return titles\n",
    "\n",
    "def retrieve_ratings(soup):\n",
    "    ratings = []\n",
    "    rating_tags = soup.find_all('p', class_='star-rating')\n",
    "    rating_map = {'One': 1, 'Two': 2, 'Three': 3, 'Four': 4, 'Five': 5}\n",
    "    for rating_tag in rating_tags:\n",
    "        rating = rating_map[rating_tag.get('class')[-1]]\n",
    "        ratings.append(rating)\n",
    "    return ratings\n",
    "\n",
    "def retrieve_availabilities(soup):\n",
    "    availabilities = []\n",
    "    availability_tags = soup.find_all('p', class_='instock availability')\n",
    "    for availability_tag in availability_tags:\n",
    "        availabilities.append(availability_tag.text.strip())\n",
    "    return availabilities\n",
    "\n",
    "def get_next_page_url(soup):\n",
    "    next_button = soup.find('li', class_='next')\n",
    "    if next_button:\n",
    "        next_page_url = next_button.a['href']\n",
    "        return \"http://books.toscrape.com/catalogue/\" + next_page_url\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df = pd.DataFrame()\n",
    "url = \"http://books.toscrape.com/catalogue/page-1.html\"\n",
    "while url:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    titles = retrieve_titles(soup)\n",
    "    star_ratings = retrieve_ratings(soup)\n",
    "    prices = retrieve_prices(soup)\n",
    "    availabilities = retrieve_availabilities(soup)\n",
    "    \n",
    "    min_length = min(len(titles), len(star_ratings), len(prices), len(availabilities))\n",
    "    titles = titles[:min_length]\n",
    "    star_ratings = star_ratings[:min_length]\n",
    "    prices = prices[:min_length]\n",
    "    availabilities = availabilities[:min_length]\n",
    "    \n",
    "    page_df = pd.DataFrame({\n",
    "        'Title': titles,\n",
    "        'Star Rating': star_ratings,\n",
    "        'Price': prices,\n",
    "        'Availability': availabilities\n",
    "    })\n",
    "    df = pd.concat([df, page_df], ignore_index=True)\n",
    "    \n",
    "    # Get the URL of the next page\n",
    "    url = get_next_page_url(soup)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('books_data.csv', index=False)\n",
    "\n",
    "print(\"Scraping and saving complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Well done! You just completed your first full web scraping project! You're ready to start harnessing the power of the web!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
